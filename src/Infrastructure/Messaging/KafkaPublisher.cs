using System.Text.Json;
using Microsoft.Extensions.Configuration;
using Microsoft.Extensions.Logging;

using Confluent.Kafka;

using Payments.Application.Interfaces;

namespace Payments.Infrastructure.Messaging;

public sealed class KafkaPublisher : IMessagePublisher, IDisposable
{
    private readonly IProducer<string, string> _producer;
    private readonly ILogger<KafkaPublisher> _logger;

    public KafkaPublisher(IConfiguration config, ILogger<KafkaPublisher> logger)
    {
        _logger = logger;

        var producerConfig = new ProducerConfig
        {
            BootstrapServers = config["Kafka:BootstrapServers"] ?? "kafka:9092",

            // Critical settings for better failover handling    
            Acks = Enum.Parse<Acks>(config["Kafka:Acks"] ?? "Leader"),

            // Improve broker discovery and failover    
            SocketConnectionSetupTimeoutMs = int.TryParse(config["Kafka:SocketConnectionSetupTimeoutMs"], out var socketConnectionSetupTimeoutMs) ? socketConnectionSetupTimeoutMs : 10000,
            SocketTimeoutMs = int.TryParse(config["Kafka:SocketTimeoutMs"], out var socketTimeoutMs) ? socketTimeoutMs : 5000,

            // Retry settings    
            MessageSendMaxRetries = int.TryParse(config["Kafka:MessageSendMaxRetries"], out var messageSendMaxRetries) ? messageSendMaxRetries : 5,
            RetryBackoffMs = int.TryParse(config["Kafka:RetryBackoffMs"], out var retryBackoffMs) ? retryBackoffMs : 100,
            ReconnectBackoffMs = int.TryParse(config["Kafka:ReconnectBackoffMs"], out var reconnectBackoffMs) ? reconnectBackoffMs : 50,
            ReconnectBackoffMaxMs = int.TryParse(config["Kafka:ReconnectBackoffMaxMs"], out var reconnectBackoffMaxMs) ? reconnectBackoffMaxMs : 5000,

            // Reasonable timeouts    
            RequestTimeoutMs = int.TryParse(config["Kafka:RequestTimeoutMs"], out var requestTimeoutMs) ? requestTimeoutMs : 5000,
            MessageTimeoutMs = int.TryParse(config["Kafka:MessageTimeoutMs"], out var messageTimeoutMs) ? messageTimeoutMs : 15000,

            //MaxInFlight = 5,

            //EnableIdempotence = true,
            
        };

        _producer = new ProducerBuilder<string, string>(producerConfig).Build();
    }

    public async Task PublishJsonAsync<T>(
        string route,
        string key,
        T payload,
        IEnumerable<KeyValuePair<string, string>>? headers = null,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var json = JsonSerializer.Serialize(payload);

            var msg = new Message<string, string>
            {
                Key = key ?? string.Empty,
                Value = json,
                Headers = new Headers()
            };

            if (headers is not null)
            {
                foreach (var h in headers)
                    msg.Headers!.Add(h.Key, System.Text.Encoding.UTF8.GetBytes(h.Value));
            }

            var result = await _producer.ProduceAsync(route, msg, cancellationToken);
           
            _logger.LogDebug("Produced to {TP} (offset {Offset})", result.TopicPartition, result.Offset);
        }
        catch (ProduceException<string, string> ex)
        {
            _logger.LogError(ex, "Kafka produce error: {Reason}", ex.Error.Reason);
            throw;
        }
    }

    public void Dispose()
    {
        try { _producer.Flush(TimeSpan.FromSeconds(5)); }
        catch (Exception ex) { _logger.LogWarning(ex, "Error flushing Kafka producer during dispose"); }
        finally { _producer.Dispose(); }
    }
}
